{% extends "project_detail.html" %}
{% load static %}
{% block project_content %}
<div id="usage" class="container-fluid bg-secondary p-5 getZooped">
    <h1 class="text-center">Usage</h1>
    <hr class="p-2">
    <div class="row align-items-center justify-content-md-center gap-5">
        <div class="col-lg-5">
            <p>First, install the package with pip:</p>
            <div class="container-fluid text-primary bg-primary-subtle p-3 rounded shadow" style="font-family:'Consolas'">
                pip install tfhub-styletransfer-wrapper
            </div>
            <br>
            <hr>
            <p>Then, import the package:</p>
            <div class="container-fluid text-primary bg-primary-subtle p-3 rounded shadow" style="font-family:'Consolas'">
                from tfhub_styletransfer_wrapper import StyleHub
            </div>
            <br>
            <hr>
            <p>Initiate the StyleHub module, and load the content and style images:</p>
            <div class="container-fluid text-primary bg-primary-subtle p-3 rounded shadow" style="font-family:'Consolas'">
                stylehub = StyleHub() <br>
                stylehub.load_content(content_filename, 512) <br>
                stylehub.load_style(style_filename, 256) <br>
            </div>
            <br>
            <hr>
            <p>To evaluate the model: </p>
            <div class="container-fluid text-primary bg-primary-subtle p-3 rounded shadow" style="font-family:'Consolas'">
                stylized_image = stylehub.evaluate()
            </div>
            <br>
            <hr>
            <p>And to save the stylized output:</p>
            <div class="container-fluid text-primary bg-primary-subtle p-3 rounded shadow" style="font-family:'Consolas'">
                from tfhub_styletransfer_wrapper import save_image <br>
                save_image(stylized_image, output_filename)
            </div>
            <br>
        </div>
    </div>
</div>
<div class="container-fluid bg-dark py-5">
    <div class="d-grid gap-2">
        <a class="btn p-4" href="#" role="button"><h5><i class="bi bi-arrow-bar-up"></i></h5></a>
    </div>
</div>
<div id="results" class="container-fluid bg-secondary p-5 getZooped">
    <h1 class="text-center">Results</h1>
    <hr class="p-2">
    <div class="row align-items-center justify-content-md-center gap-5">
        <div class="col-lg-5">
            <a href="{% static 'img/styletransfer-example1.jpg' %}" target="_blank">
                <img class="img-fluid rounded" src="{% static 'img/styletransfer-example1.jpg' %}">
            </a>
        </div>
        <div class="col-lg-5">
            <a href="{% static 'img/styletransfer-example2.jpg' %}" target="_blank">
                <img class="img-fluid rounded" src="{% static 'img/styletransfer-example2.jpg' %}">
            </a>
        </div>
        <div class="col-lg-5">
            <a href="{% static 'img/styletransfer-example3.jpg' %}" target="_blank">
                <img class="img-fluid rounded" src="{% static 'img/styletransfer-example3.jpg' %}">
            </a>
        </div>
        <div class="col-lg-5">
            <a href="{% static 'img/styletransfer-example4.jpg' %}" target="_blank">
                <img class="img-fluid rounded" src="{% static 'img/styletransfer-example4.jpg' %}">
            </a>
        </div>
    </div>
</div>
<div class="container-fluid bg-dark py-5">
    <div class="d-grid gap-2">
        <a class="btn p-4" href="#" role="button"><h5><i class="bi bi-arrow-bar-up"></i></h5></a>
    </div>
</div>
<div id="how-it-works" class="container-fluid bg-secondary p-5 getZooped">
    <h1 class="text-center">How It Works</h1>
    <hr class="p-2">
    <div class="row align-items-center justify-content-lg-center gap-5">
        <div class="col-lg-7">
            <p align="justify" class="shadow rounded p-3 bg-primary-subtle">The image to the below shows the structure for the arbitrary style transfer model. The style prediction network P predicts an embedding vector S from an input style image, which supplies a set of normalization constants for the style transfer network.</p>
        </div>
    </div>
    <div class="row align-items-center justify-content-lg-center gap-5">
        <div class="col-lg-4">
            <div class="card border-primary text-white bg-primary-subtle mb-2">
                <div class="noOverflow">
                    <a href="{% static 'img/fast_style_transfer_arch-3.jpg' %}" target="_blank">
                        <img class="card-img-top" src="{% static 'img/fast_style_transfer_arch-3.jpg' %}">
                    </a>
                </div>
                <div class="card-body">
                    <h5 class="card-text"><em>Style Transfer Model</em></h5>
                </div>
            </div>
        </div>
    </div>
    <br>
    <div class="row align-items-center justify-content-lg-center gap-5">
        <div class="col-lg-7">
            <p align="justify" class="shadow rounded p-3 bg-primary-subtle">The style prediction network P is based on the Inception-v3 architecture and was developed as a way to scale up network architectures and avoid some of the increase in computational complexity that arises. Developed as an alternative to VGGNet, the Inception architecture offers improvements by avoiding representational bottlenecks, processing higher dimensional representations locally within a network (increasing the activations per tile), and factorizing large convolution filters into smaller ones.</p>
        </div>
    </div>
    <div class="row align-items-center justify-content-lg-center gap-5">
        <div class="col-lg-6">
            <div class="card border-primary text-white bg-primary-subtle mb-2">
                <div class="noOverflow">
                    <a href="{% static 'img/inceptionv3.png' %}" target="_blank">
                        <img class="card-img-top" src="{% static 'img/inceptionv3.png' %}">
                    </a>
                </div>
                <div class="card-body">
                    <h5 class="card-text"><em>Inception-v3 Model</em></h5>
                </div>
            </div>
        </div>
    </div>
    <br>
    <div class="row align-items-center justify-content-lg-center gap-5">
        <div class="col-lg-7">
            <p align="justify" class="shadow rounded p-3 bg-primary-subtle">The Inception-v3 model (pictured above) is made up of both symmetric and asymmetric blocks like convolutions, average pooling, max pooling, concatinations, dropouts, and fully connected layers. Typically, each layer implements batch normalization, and the loss is computed using Softmax.</p>
        </div>
    </div>
    <div class="row align-items-center justify-content-lg-center gap-5">
        <div class="col-lg-7">
            <p align="justify" class="shadow rounded p-3 bg-primary-subtle">The style transfer network T is a convolutional neural network formulated in the structure of an image encoder/decoder. The mean is computed across each channel of the Inception-v3 output S, which is then connected to two fully connected networks to predict the final embeddings. The overall effect of the style transfer network is that it will shift the mean and variance of the content image in an attempt to match the mean and variance of the style image's features.</p>
        </div>
    </div>
</div>
<div class="container-fluid bg-dark py-5">
    <div class="d-grid gap-2">
        <a class="btn p-4" href="#" role="button"><h5><i class="bi bi-arrow-bar-up"></i></h5></a>
    </div>
</div>
<div id="references" class="container-fluid bg-secondary p-5 getZooped">
    <h1 class="text-center">References</h1>
    <hr class="p-2">
    <div class="row align-items-center justify-content-md-center gap-5">
        <div class="col-lg-6 shadow rounded p-3 bg-primary-subtle">
            <p>Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens. <a href="https://arxiv.org/abs/1705.06830" class="link-underline-primary">Exploring the structure of a real-time, arbitrary neural artistic stylization network</a>. Proceedings of the British Machine Vision Conference (BMVC), 2017.</p>
            <p>Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna. <a href="https://arxiv.org/abs/1512.00567" class="link-underline-primary">Rethinking the Inception Architecture for Computer Vision</a>. In IEEE Computer Vision and Pattern Recognition (CVPR), 2015.</p>
            <p>Xun Huang, Serge Belongie. <a href="https://arxiv.org/abs/1703.06868" class="link-underline-primary">Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization</a>. In ICCV, 2017</p>
        </div>
    </div>
</div>
<div id="asd" class="container-fluid bg-dark p-5 getZooped">
    <div class="row align-items-start justify-content-md-center gap-5">

    </div>
</div>
{% endblock %}